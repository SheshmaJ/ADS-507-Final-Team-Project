# GitHub Actions workflow for pipeline monitoring.

# This workflow provides a one click end to end execution of data pipeline
#using github actions.It runs full ingestion,transformation, and loading,followed
#by monitoring checks to ensure data quality.
#This allows reproducible pipeline execution without local setup.
#It allows pipeline to be triggered manually from github.
#Helps to generate monitoring reports for data quality validation.



name: Pipeline Monitoring

on:
  workflow_dispatch:

jobs:
  pipeline-monitor:
    runs-on: ubuntu-latest

    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_DATABASE: fda_shortage_db
          MYSQL_USER: pipeline_user
          MYSQL_PASSWORD: pipeline_password
          MYSQL_ROOT_PASSWORD: rootpassword
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping -h 127.0.0.1 -prootpassword"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=30

    env:
      DB_USER: pipeline_user
      DB_PASSWORD: pipeline_password
      DB_HOST: 127.0.0.1
      DB_PORT: "3306"
      DB_NAME: fda_shortage_db
      

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y mysql-client

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install playwright
          python -m playwright install --with-deps chromium

      - name: Wait for MySQL to be ready
        run: |
          for i in {1..60}; do
            mysql -h "$DB_HOST" -P "$DB_PORT" -u "$DB_USER" -p"$DB_PASSWORD" -e "SELECT 1" "$DB_NAME" && break
            echo "Waiting for MySQL..."
            sleep 2
          done

      - name: Create schema tables
        run: |
          mysql -h "$DB_HOST" -P "$DB_PORT" -u "$DB_USER" -p"$DB_PASSWORD" "$DB_NAME" < sql/01_create_tables.sql

      - name: Run pipeline (writes monitoring/reports/pipeline.log)
        run: |
          python run_pipeline.py

      - name: Run monitoring checks 
        run: |
          python monitoring/run_monitoring.py
        continue-on-error: true  

      - name: Capture Streamlit screenshot
        run: |
          python scripts/capture_dashboard.py

      - name: Upload pipeline artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-artifacts
          path: monitoring/reports/
